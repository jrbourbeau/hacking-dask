{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d19f489-59e6-48c7-aade-25530dcf253c",
   "metadata": {},
   "source": [
    "# Hacking Dask clusters\n",
    "\n",
    "In this notebook we'll cover:\n",
    "\n",
    "- Cluster overview\n",
    "- Inspecting a cluster's state\n",
    "- Dynamic hooks: worker and scheduler plugins\n",
    "- Handlers\n",
    "- Coordination primatives: `Lock`, `Event`, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45762cb-a5a2-4f7c-ae29-02f05c78ba89",
   "metadata": {},
   "source": [
    "# Cluster overview\n",
    "\n",
    "In this section we'll discuss:\n",
    "\n",
    "1. The different components which make up a Dask cluster\n",
    "2. How to launch a cluster\n",
    "\n",
    "## Components of a cluster\n",
    "\n",
    "A Dask cluster is composed of three different types of objects:\n",
    "\n",
    "1. **Scheduler**: A single, centralized scheduler which responds to requests for computations and manages ...\n",
    "2. **Workers**: One or more worker processes which compute, store, and serve computational results\n",
    "3. **Clients**: One or more client objects which are the user-facing entry point to interact with the cluster\n",
    "\n",
    "<img src=\"images/dask-cluster.svg\"\n",
    "     width=\"60%\"\n",
    "     alt=\"Dask components\\\">\n",
    "\n",
    "## Deploying Dask clusters\n",
    "\n",
    "Deploying a Dask cluster means launching scheduler, worker, and client processes and setting up the appropriate network connections so these processes can communicate with one another. Dask clusters can be lauched in a few different ways which we highlight in the following sections.\n",
    "\n",
    "### Manual setup\n",
    "\n",
    "Launch a scheduler process using the `dask-scheduler` command line utility:\n",
    "\n",
    "```terminal\n",
    "$ dask-scheduler\n",
    "Scheduler at:   tcp://192.0.0.100:8786\n",
    "```\n",
    "\n",
    "and then launch several workers by using the `dask-worker` command and providing them the address of the scheduler they should connect to:\n",
    "\n",
    "```terminal\n",
    "$ dask-worker tcp://192.0.0.100:8786\n",
    "Start worker at:  tcp://192.0.0.1:12345\n",
    "Registered to:    tcp://192.0.0.100:8786\n",
    "\n",
    "$ dask-worker tcp://192.0.0.100:8786\n",
    "Start worker at:  tcp://192.0.0.2:40483\n",
    "Registered to:    tcp://192.0.0.100:8786\n",
    "\n",
    "$ dask-worker tcp://192.0.0.100:8786\n",
    "Start worker at:  tcp://192.0.0.3:27372\n",
    "Registered to:    tcp://192.0.0.100:8786\n",
    "```\n",
    "\n",
    "### Python API (advanced)\n",
    "\n",
    "⚠️ **Warning**: Creating `Scheduler` / `Worker` objects explicitly in Python is only needed in rare circumstances and is intended for expert users ⚠️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac63e3e5-e75f-4ebd-b1ff-4619a7e6f5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Scheduler, Worker, Client\n",
    "\n",
    "# Launch a scheduler\n",
    "async with Scheduler() as scheduler: # Launch a scheduler\n",
    "    # Launch a worker which connects to the scheduler\n",
    "    async with Worker(scheduler.address) as worker:\n",
    "        # Launch a client which connects to the scheduler\n",
    "        async with Client(scheduler.address, asynchronous=True) as client:\n",
    "            result = await client.submit(sum, range(100))\n",
    "            print(f\"{result = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8031ac-58a0-40bb-a0b1-07847d54b964",
   "metadata": {},
   "source": [
    "### Cluster managers (recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77fbd0f-720a-48e2-aa07-fd9d9a01f381",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import LocalCluster\n",
    "\n",
    "# Launch a scheduler and 4 workers on my local machine\n",
    "cluster = LocalCluster(n_workers=4, threads_per_worker=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41daa9b9-51c5-4996-85a5-144f19714389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale up to 10 workers\n",
    "cluster.scale(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8937b5b-2559-4eb1-96ae-d76b385526c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale down to 2 workers\n",
    "cluster.scale(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e350ead3-229a-4974-bd89-7174d99edbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94169465-79c0-4063-b7bf-dbc9264cdfe4",
   "metadata": {},
   "source": [
    "There are several projects in the Dask ecosystem for easily deploying clusters on commonly used computing resources:\n",
    "\n",
    "- [Dask-Kubernetes](https://kubernetes.dask.org/en/latest/) for deploying Dask using native Kubernetes APIs\n",
    "- [Dask-Cloudprovider](https://cloudprovider.dask.org/en/latest/) for deploying Dask clusters on various cloud platforms (e.g. AWS, GCP, Azure, etc.)\n",
    "- [Dask-Yarn](https://yarn.dask.org/en/latest/) for deploying Dask on YARN clusters\n",
    "- [Dask-MPI](http://mpi.dask.org/en/latest/) for deploying Dask on existing MPI environments\n",
    "- [Dask-Jobqueue](https://jobqueue.dask.org/en/latest/) for deploying Dask on job queuing systems (e.g. PBS, Slurm, etc.)\n",
    "\n",
    "Launching clusters with any of these projects follows a similar pattern as using Dask's built-in `LocalCluster`:\n",
    "\n",
    "```python\n",
    "# Launch a Dask cluster on a Kubernetes cluster\n",
    "from dask_kubernetes import KubeCluster\n",
    "cluster = KubeCluster(...)\n",
    "\n",
    "# Launch a Dask cluster on AWS Fargate\n",
    "from dask_cloudprovider.aws import FargateCluster\n",
    "cluster = FargateCluster(...)\n",
    "\n",
    "# Launch a Dask cluster on a PBS job queueing system\n",
    "from dask_jobqueue import PBSCluster\n",
    "cluster = PBSCluster()\n",
    "```\n",
    "\n",
    "We'll discuss this more throughout the course of this tutorial, but if you're interested in learning more about the various steps involved in computing a task we recommended checking out the [*Journey of a Task*](https://distributed.dask.org/en/latest/journey.html) page in the Dask documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f774c1-bf94-4614-996c-168e814ae954",
   "metadata": {},
   "source": [
    "# Inspecting a cluster's state\n",
    "\n",
    "In this section we'll:\n",
    "\n",
    "1. Familiarize ourselves with Dask's scheduler and worker processes\n",
    "2. Explore the various state that's tracked throughout the cluster\n",
    "\n",
    "Let's start by creating a local cluster and perform a small computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4073fc4-62ed-4ac3-9007-e8a78b96e46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import LocalCluster, Client\n",
    "\n",
    "cluster = LocalCluster()\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cd7868-ceb2-4066-bb8f-094ad3fc0053",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "\n",
    "x = da.random.random((100, 100), chunks=(50, 50))\n",
    "x = x.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8a3c19-97d2-47a9-8216-3f73abe6189a",
   "metadata": {},
   "source": [
    "One of the nice things about a `LocalCluster` is it gives us direct access the `Scheduler` Python object. This allows us to easily inspect the scheduler directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b842c4f-64c6-4a0b-b068-45332552d6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = cluster.scheduler\n",
    "type(scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8e8155-68a2-4cfc-8cfb-424180e98bdb",
   "metadata": {},
   "source": [
    "ℹ️ Note that often times you won't have direct access to the `Scheduler` Python object (e.g. when the scheduler is running on separate machine). In these cases it's still possible to inspect the scheduler and we will discuss how to do this later on.\n",
    "\n",
    "The scheduler tracks **a lot** of state. Let's start to explore the scheduler to get a sense for what information it keeps track of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a43b6c-210c-41a0-bfff-38c38bfb6316",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler.address   # Scheduler's address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb25dc76-df8c-418e-84ea-ba3d33fcd373",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler.time_started   # Time the scheduler was started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c8b1be-3adb-4cdd-893c-f83d71a75a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(scheduler.workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f68f77-69c6-4b17-90ce-cf179af7d287",
   "metadata": {},
   "outputs": [],
   "source": [
    "worker_state = next(iter(scheduler.workers.values()))\n",
    "worker_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1dffd1e-1d3e-43a0-a234-76c6fb015566",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(worker_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ba8180-8ef7-4bc7-ae0a-cf7b9708c9e6",
   "metadata": {},
   "source": [
    "Let's take a look at the `WorkerState` attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf806b73-e423-4770-846c-26a4f6aee6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "[attr for attr in dir(worker_state) if not attr.startswith(\"_\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73d206f-7a65-49f0-8361-3f9e37f5a73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "worker_state.address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d58de4-ec72-4d16-a77b-f35a05d74563",
   "metadata": {},
   "outputs": [],
   "source": [
    "worker_state.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24be2aab-a7c7-454d-91f9-78897e32eadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "worker_state.processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bbacd5-a368-4566-912c-4a4db4b8a211",
   "metadata": {},
   "source": [
    "Workers periodically send a message "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf2af29-be3e-4d78-a5c2-ca595d380357",
   "metadata": {},
   "outputs": [],
   "source": [
    "worker_state.last_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be601b2d-7047-44b2-81c2-5dabd344053c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "for _ in range(10):\n",
    "    print(f\"{worker_state.last_seen = }\")\n",
    "    time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e414215-dc91-4468-af2f-4119945bca3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "worker_state.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fca292-9fda-4c00-b2b9-693c40f49dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler.total_nthreads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b05ace-1e10-4716-ae83-f7c659c46d28",
   "metadata": {},
   "source": [
    "# Scheduler and worker plugins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c58042-3b73-43bf-9eb0-dddf0b4c14e4",
   "metadata": {},
   "source": [
    "# Coordination Primitives"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
